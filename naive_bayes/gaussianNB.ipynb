{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e67af9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "import numpy as np\n",
    "\n",
    "class GaussianNB:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y) # List of unique labels\n",
    "        n_features = X.shape[1] \n",
    "        n_classes = len(self.classes)\n",
    "\n",
    "        self.means = np.zeros((n_classes, n_features)) # Stores feature mean class-wise\n",
    "        self.vars = np.zeros((n_classes, n_features)) # Stores feature variance class-wise\n",
    "        self.class_log_prior = np.zeros(n_classes) # Stores class prior(probability)\n",
    "\n",
    "        for idx, c in enumerate(self.classes):\n",
    "            X_c = X[y == c]\n",
    "            self.means[idx, :] = np.mean(X_c, axis=0)\n",
    "            self.vars[idx, :] = np.var(X_c, axis=0)  #adding epilson to prevent division from 0.\n",
    "            self.class_log_prior[idx] = np.log(X_c.shape[0] / X.shape[0])\n",
    "\n",
    "    def _log_likelihood(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        n_classes = len(self.classes)\n",
    "        log_probs =np.zeros((n_samples, n_classes))\n",
    "\n",
    "        for idx, c in enumerate(self.classes):\n",
    "            mean = self.means[idx] #Features mean class-wise\n",
    "            var = self.vars[idx] #Features variance class-wise\n",
    "            log_prob = -0.5 * np.sum(np.log(2 * np.pi * var)) # log(1/root(2.var.pi)) = log((2.var.pi)**-1/2)  \n",
    "            log_prob -= 0.5 * np.sum(((X - mean) ** 2 ) / var , axis=1)\n",
    "            log_probs[: , idx] = self.class_log_prior[idx] + log_prob\n",
    "        \n",
    "        return log_probs\n",
    "    \n",
    "    def predict(self, X):\n",
    "        log_probs = self._log_likelihood(X)\n",
    "        return self.classes[np.argmax(log_probs, axis=1)]    \n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3aa07b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import sklearn.naive_bayes\n",
    "\n",
    "# Create synthetic data\n",
    "X, y = make_classification(n_samples=200, n_features=2,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           n_classes=2, random_state=42)\n",
    "\n",
    "# Train\n",
    "gnb = GaussianNB()\n",
    "sk_gnb = sklearn.naive_bayes.GaussianNB()\n",
    "\n",
    "gnb.fit(X, y)\n",
    "sk_gnb.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "y_pred = gnb.predict(X)\n",
    "y_pred_sk = sk_gnb.predict(X)\n",
    "\n",
    "# Check accuracy\n",
    "accuracy = np.mean(y_pred == y)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "accuracy_sk = np.mean(y_pred_sk == y)\n",
    "print(f\"Accuracy: {accuracy_sk:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
